{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from kLSTM import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, device, train_loader, optimizer, config, epoch):\n",
    "    model.train()   # set model in training mode\n",
    "    losses = []\n",
    "    scores = []\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = torch.squeeze(X, 1)  # remove grey-level channel of MNIST\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, layer_z_T, layer_qz_T, layer_h_T, _ = model(X, config.tau, is_training=True)\n",
    "        '''layer_qz_T= qz_T in last layer'''\n",
    "\n",
    "        # computing entropy loss\n",
    "        entropy = - layer_qz_T * torch.log(layer_qz_T + 1e-20)\n",
    "        loss2 = torch.mean(torch.sum(entropy, (1, 2)))\n",
    "\n",
    "        # define total loss\n",
    "        if config.obj == 'ER':\n",
    "            loss = F.cross_entropy(output, y) - config.beta * loss2\n",
    "        elif config.obj == 'VB':\n",
    "            loss = F.cross_entropy(output, y) - loss2\n",
    "        elif config.obj == 'MLE':\n",
    "            loss = F.cross_entropy(output, y)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # to compute accuracy\n",
    "        y_pred = torch.max(output, 1)[1]  # convert output -> y_pred\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(-config.lr, p.grad.data)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # show information\n",
    "        if batch_idx % config.log_interval == 0:\n",
    "            print(\"Learning rate: {:.4f}, Temperature: {:.3f}\\n\".format(config.lr, config.tau))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch, batch_idx * len(X), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), 100 * step_score))\n",
    "\n",
    "    return losses, scores\n",
    "\n",
    "\n",
    "def validation(model, device, test_loader, config):\n",
    "    model.eval()   # set model in testing mode\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X = torch.squeeze(X, 1)  # remove grey-level channel for MNIST\n",
    "\n",
    "            output, layer_z_T, layer_qz_T, layer_h_T, _ = model(X, config.tau, is_training=False)\n",
    "            '''layer_qz_T: last layer qz_T'''\n",
    "\n",
    "            # computing entropy loss\n",
    "            entropy = - layer_qz_T * torch.log(layer_qz_T + 1e-20)\n",
    "            entropy = entropy.sum(1).sum(1).sum()\n",
    "\n",
    "            # define total loss\n",
    "            if config.obj == 'ER':\n",
    "                loss = F.cross_entropy(output, y) - config.beta * entropy\n",
    "            elif config.obj == 'VB':\n",
    "                loss = F.cross_entropy(output, y) - entropy\n",
    "            elif config.obj == 'MLE':\n",
    "                loss = F.cross_entropy(output, y)\n",
    "\n",
    "            test_loss += loss.item()                 # sum up batch loss\n",
    "            y_pred = output.max(1, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
    "\n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # to compute accuracy\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show info\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100 * test_score))\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    init_scale = 0.1\n",
    "    epochs = 10\n",
    "    batch_size = 150\n",
    "    display_step = 100\n",
    "    lr = 1e-3\n",
    "    clip = 0.25         # gradient clip threshold to avoid grdient explosion\n",
    "    vocab_size = 10000\n",
    "    tau0 = 5.0          # initial temperature\n",
    "    anneal_rate = 0.1\n",
    "    min_temp = 0.1\n",
    "    beta = 0.001\n",
    "    log_interval = 100\n",
    "    obj = 'ER'          # define MRNN loss objective, select: 'MLE','VB','ER'\n",
    "\n",
    "    # Network Parameters\n",
    "    input_size = 28\n",
    "    hidden_size = 128\n",
    "    num_class = 10\n",
    "    T = 28              # timesteps of data\n",
    "    num_layers = 3\n",
    "    K = 4               # LSTM numbers\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# output\n",
    "output_folder = './outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./MNIST/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./MNIST/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X[0, 0, :, :])\n",
    "plt.savefig('./digit.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check GPU devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# set dataloader parameters\n",
    "params = {'batch_size': config.batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# create model\n",
    "mrnn = LSTM(cell_class=LSTMCell, input_size=config.T, hidden_size=config.hidden_size,\n",
    "            output_size=config.num_class, num_layers=config.num_layers, k_cells=config.K, use_bias=True, dropout_prob=0.5).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(mrnn.parameters(), lr=config.lr)   # optimize all cnn parameters\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(config.epochs):\n",
    "    avg_cost = 0.\n",
    "\n",
    "    # adjust Gumbel softmax temp\n",
    "    config.tau = np.maximum(config.tau0 * np.exp(-config.anneal_rate * epoch), config.min_temp)\n",
    "    # training model\n",
    "    train_losses, train_scores = train(mrnn, device, train_loader, optimizer, config, epoch)\n",
    "\n",
    "for epoch in range(1):\n",
    "    # model validation\n",
    "    print('-' * 80); print('validating'); print('-' * 80)\n",
    "    epoch_test_loss, epoch_test_score = validation(mrnn, device, test_loader, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_prob = 0\n",
    "eval_config = Config()\n",
    "eval_config.batch_size = 1\n",
    "eval_config.T = 1\n",
    "\n",
    "X = test_loader.dataset.test_data.to(device)\n",
    "y = test_loader.dataset.test_labels.to(device)\n",
    "\n",
    "for i in range(eval_config.num_class):\n",
    "    # select samples of label y=i\n",
    "    X_i, y_i = X[y == i, :].float()/255.0, y[y == i]\n",
    "\n",
    "    eval_config.batch_size = X_i.shape[0]\n",
    "    with torch.no_grad():\n",
    "        output, layer_z_T, layer_qz_T, layer_h_T, _ = mrnn(X_i, eval_config.tau0, is_training=False)\n",
    "    \n",
    "    # compute probability of LSTM usage (integrating) over time and selected samples\n",
    "    prob = torch.einsum('ijk->k', (layer_z_T,)) / torch.sum(layer_z_T)\n",
    "    prob = prob.data.cpu().numpy()\n",
    "    total_prob += prob\n",
    "\n",
    "    # plot image\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X_i.data.cpu()[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plot probability(k LSTM)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(np.arange(eval_config.K) + 1, prob, alpha=0.8)\n",
    "    plt.xlabel('{} LSTMs'.format(eval_config.K))\n",
    "    plt.ylabel('Probability')\n",
    "    # plt.savefig(os.path.join(output_folder, 'digit{}_transition.png'.format(i)), dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "# plot total probability (over all classes [labels])\n",
    "total_prob = total_prob / eval_config.num_class\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(np.arange(eval_config.K) + 1, total_prob, alpha=0.8)\n",
    "plt.xlabel('{} LSTMs'.format(eval_config.K))\n",
    "plt.ylabel('Total probability (over all timesteps)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot $z(t)$ and $q_z(t)$ , where $t \\in [0, T]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_pick = 2   # random pick a sample in the same category\n",
    "\n",
    "# parameters for ploting image series\n",
    "ncols, nrows = config.T, 1\n",
    "photow, photoh = 20, 20\n",
    "marl, mart, marr, marb = 1, 1, 1, 1\n",
    "padding = True\n",
    "\n",
    "for i in range(eval_config.num_class):\n",
    "    # select samples of label y=i\n",
    "    X_i, y_i = X[y == i, :].float() / 255, y[y == i]\n",
    "\n",
    "    eval_config.batch_size = 5\n",
    "    X_i, y_i = X_i[:eval_config.batch_size], y_i[:eval_config.batch_size]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, layer_z_T, layer_qz_T, layer_h_T, _ = mrnn(X_i, eval_config.tau0, is_training=False)\n",
    "    \n",
    "    # plot MNIST digit as time series\n",
    "    A = (X_i[random_pick].data.cpu().numpy() * 255).astype(np.uint8)\n",
    "    frames = [np.zeros((config.T, config.T)).astype(np.uint8) for j in range(config.T)]\n",
    "    for j in range(config.T):\n",
    "        frames[j][j, :] = A[j, :]\n",
    "    \n",
    "    # print original image at the end\n",
    "    frames[-1] = A\n",
    "    \n",
    "    # make image as series\n",
    "    image_series = plot_image_series(frames, ncols, nrows, photow, photoh, marl, mart, marr, marb, padding)\n",
    "\n",
    "    # plot 1: image (time) series\n",
    "    plt.figure(figsize=(17, 15))\n",
    "    plt.imshow(np.asarray(image_series))\n",
    "    plt.axis('off')\n",
    "    plt.title('{}'.format(i))\n",
    "    # plt.savefig(os.path.join(output_folder, 'digit{}.png'.format(i)), dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 2: soft transition function: q_z(t)\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    plt.imshow(layer_qz_T[random_pick].data.cpu().numpy().T)\n",
    "    plt.xlabel('q_z(t)')\n",
    "    plt.ylabel('{} LSTMs'.format(eval_config.K))\n",
    "    plt.grid()\n",
    "    # plt.savefig(os.path.join(output_folder, 'qz_t_digit{}.png'.format(i)), dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    # plot 3: Gumbel sampling of transition function: z(t)\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    plt.imshow(layer_z_T[random_pick].data.cpu().numpy().T)\n",
    "    plt.xlabel('z(t)')\n",
    "    plt.ylabel('{} LSTMs'.format(eval_config.K))\n",
    "    plt.grid()\n",
    "    # plt.savefig(os.path.join(output_folder, 'z_t_digit{}.png'.format(i)), dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
